{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YaassminSalahEldin/MyProjects/blob/master/Egyptian_Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install numpy --upgrade --force-reinstall\n",
        "# import numpy as np\n"
      ],
      "metadata": {
        "id": "iiYbBulDuz05"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.4 --force-reinstall\n"
      ],
      "metadata": {
        "id": "Y0bWaElWx8YN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 428
        },
        "outputId": "b4ceeba2-fa6e-400a-c874-3e1e1b1008a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting numpy==1.26.4\n",
            "  Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "Using cached numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "Installing collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.8.0 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.0 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "81e5780f0c8248c39e0b112797340b0d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a76e068f",
        "outputId": "c6c06c85-9d6a-47f6-fa2c-2049bade6564"
      },
      "source": [
        "!pip install torchtext==0.16.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torchtext==0.16.0 in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (2.32.3)\n",
            "Collecting torch==2.1.0 (from torchtext==0.16.0)\n",
            "  Using cached torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl.metadata (25 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (1.26.4)\n",
            "Requirement already satisfied: torchdata==0.7.0 in /usr/local/lib/python3.11/dist-packages (from torchtext==0.16.0) (0.7.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (4.14.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch==2.1.0->torchtext==0.16.0) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-nccl-cu12==2.18.1 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting triton==2.1.0 (from torch==2.1.0->torchtext==0.16.0)\n",
            "  Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.7.0->torchtext==0.16.0) (2.5.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch==2.1.0->torchtext==0.16.0) (12.8.93)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchtext==0.16.0) (2025.8.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.1.0->torchtext==0.16.0) (3.0.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->torch==2.1.0->torchtext==0.16.0) (1.3.0)\n",
            "Using cached torch-2.1.0-cp311-cp311-manylinux1_x86_64.whl (670.2 MB)\n",
            "Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Using cached nvidia_nccl_cu12-2.18.1-py3-none-manylinux1_x86_64.whl (209.8 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Using cached triton-2.1.0-0-cp311-cp311-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89.2 MB)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.8.0\n",
            "    Uninstalling torch-2.8.0:\n",
            "      Successfully uninstalled torch-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.23.0 requires torch==2.8.0, but you have torch 2.1.0 which is incompatible.\n",
            "torchaudio 2.8.0 requires torch==2.8.0, but you have torch 2.1.0 which is incompatible.\n",
            "libcuvs-cu12 25.6.1 requires nvidia-nccl-cu12>=2.19, but you have nvidia-nccl-cu12 2.18.1 which is incompatible.\n",
            "raft-dask-cu12 25.6.0 requires nvidia-nccl-cu12>=2.19, but you have nvidia-nccl-cu12 2.18.1 which is incompatible.\n",
            "libraft-cu12 25.6.0 requires nvidia-nccl-cu12>=2.19, but you have nvidia-nccl-cu12 2.18.1 which is incompatible.\n",
            "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.18.1 nvidia-nvtx-cu12-12.1.105 torch-2.1.0 triton-2.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64f4ea53",
        "outputId": "12783138-3b28-45bc-dcdc-de7430390e2e"
      },
      "source": [
        "# Reinstall torch and related libraries to ensure compatibility\n",
        "!pip uninstall torch torchvision torchaudio -y\n",
        "!pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --quiet"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.1.0\n",
            "Uninstalling torch-2.1.0:\n",
            "  Successfully uninstalled torch-2.1.0\n",
            "Found existing installation: torchvision 0.23.0\n",
            "Uninstalling torchvision-0.23.0:\n",
            "  Successfully uninstalled torchvision-0.23.0\n",
            "Found existing installation: torchaudio 2.8.0\n",
            "Uninstalling torchaudio-2.8.0:\n",
            "  Successfully uninstalled torchaudio-2.8.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j92ynmFPpIsx",
        "outputId": "1f4d5663-7a45-4801-9bef-1f7dd39ebefb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "splits = {'train': 'train_data (1).csv', 'test': 'test_data (1).csv'}\n",
        "df_train = pd.read_csv(\"hf://datasets/Abdalrahmankamel/Egyption_2_English/\" + splits[\"train\"])\n",
        "df_test = pd.read_csv(\"hf://datasets/Abdalrahmankamel/Egyption_2_English/\" + splits[\"test\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "id": "BeoKdiI2pKRs",
        "outputId": "4e3b3e0d-1619-494d-90c1-46d54a980021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           egyption_Text  \\\n",
              "0                                               يلا فين؟   \n",
              "1                              حضرتك تقصد شخص عايش يعني؟   \n",
              "2                 وجه واحد اشجع مني شوية وسبقني واتجوزها   \n",
              "3                                  أنا محتاج أتكلم معاكي   \n",
              "4      الأمير الصغير ماقدرش يوصل لفايدة عامود نور ورا...   \n",
              "...                                                  ...   \n",
              "19639                 القبيلة تخاف من حارس الكهف، العساس   \n",
              "19640         خلي تكالك على الفتاح وأرزق يا معين يا سلام   \n",
              "19641                                         سمعته حلوة   \n",
              "19642  الفرق ما بيني وبينك بس إن أنا في الوقت اللي بع...   \n",
              "19643                    لإن أنا دايما كنت بأحل المتاهات   \n",
              "\n",
              "                                            english_Text  \n",
              "0                                              Go where?  \n",
              "1                     Do you mean, like, someone living?  \n",
              "2      Then, someone came along and married her inste...  \n",
              "3                                       We need to talk.  \n",
              "4      The little prince was not able to reach any ex...  \n",
              "...                                                  ...  \n",
              "19639         The tribe is afraid of the cave custodian.  \n",
              "19640  Count on God, the Opener of the Gates of Profi...  \n",
              "19641                          It has a good reputation.  \n",
              "19642  The difference between us is that while I'm tr...  \n",
              "19643                   You know I used to solve mazes.   \n",
              "\n",
              "[19644 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abc177ec-1ae9-46aa-b093-2fcaf87f44d3\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>egyption_Text</th>\n",
              "      <th>english_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>يلا فين؟</td>\n",
              "      <td>Go where?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>حضرتك تقصد شخص عايش يعني؟</td>\n",
              "      <td>Do you mean, like, someone living?</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>وجه واحد اشجع مني شوية وسبقني واتجوزها</td>\n",
              "      <td>Then, someone came along and married her inste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>أنا محتاج أتكلم معاكي</td>\n",
              "      <td>We need to talk.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الأمير الصغير ماقدرش يوصل لفايدة عامود نور ورا...</td>\n",
              "      <td>The little prince was not able to reach any ex...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19639</th>\n",
              "      <td>القبيلة تخاف من حارس الكهف، العساس</td>\n",
              "      <td>The tribe is afraid of the cave custodian.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19640</th>\n",
              "      <td>خلي تكالك على الفتاح وأرزق يا معين يا سلام</td>\n",
              "      <td>Count on God, the Opener of the Gates of Profi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19641</th>\n",
              "      <td>سمعته حلوة</td>\n",
              "      <td>It has a good reputation.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19642</th>\n",
              "      <td>الفرق ما بيني وبينك بس إن أنا في الوقت اللي بع...</td>\n",
              "      <td>The difference between us is that while I'm tr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19643</th>\n",
              "      <td>لإن أنا دايما كنت بأحل المتاهات</td>\n",
              "      <td>You know I used to solve mazes.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19644 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abc177ec-1ae9-46aa-b093-2fcaf87f44d3')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abc177ec-1ae9-46aa-b093-2fcaf87f44d3 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abc177ec-1ae9-46aa-b093-2fcaf87f44d3');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-b97c6072-a874-48df-83c5-e4c145cfe214\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-b97c6072-a874-48df-83c5-e4c145cfe214')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-b97c6072-a874-48df-83c5-e4c145cfe214 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_af7090b9-0132-4854-850c-90efbe5008be\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_train')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_af7090b9-0132-4854-850c-90efbe5008be button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_train');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 19644,\n  \"fields\": [\n    {\n      \"column\": \"egyption_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14384,\n        \"samples\": [\n          \"\\u0644\\u0643\\u0646 \\u0643\\u0627\\u0646 \\u0628\\u0627\\u064a\\u0646\\u0644\\u064a \\u0625\\u0646 \\u0645\\u0648\\u0647\\u0628\\u062a\\u0647 \\u0623\\u0642\\u0644 \\u0628\\u0643\\u062b\\u064a\\u0631 \\u0645\\u0646 \\u0645\\u0648\\u0647\\u0628\\u0629 \\u0648\\u0643\\u064a\\u0644 \\u0627\\u0644\\u0646\\u064a\\u0627\\u0628\\u0629. \",\n          \"\\u202b\\u0634\\u0631\\u0641\\u062a\\u064a\\u0646\\u064a.\\u202c\",\n          \"\\u0645 \\u0627\\u0644\\u0639\\u0627\\u0644\\u0645 \\u0643\\u0644\\u0647 \\u062e\\u062f\\u0648\\u0646\\u064a\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"english_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 17283,\n        \"samples\": [\n          \"Part Two \",\n          \"He adjusted the sack and carefully worked the line so that it came across a new part of his shoulders and, holding it anchored with his shoulders, he carefully felt the pull of the fish and then felt with his hand the progress of the skiff through the water.\",\n          \"He's handsome, too.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "AzzJMJVWpKKj",
        "outputId": "d077277e-6065-45b7-ac92-dd9b2006c074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    egyption_Text  \\\n",
              "0            كالعادة رفعت ما بيعرفش يلعب استغماية   \n",
              "1     مانقدروش نخشوا الكهف قبل ما نستأذنوا العساس   \n",
              "2                             ‫صح، إنتي عندك حق.‬   \n",
              "3              بس أنت لازم تشتري قمصان جديدة، هه؟   \n",
              "4                                     اهلا بحضرتك   \n",
              "...                                           ...   \n",
              "2451                        ما أنا عارفة كل حاجة.   \n",
              "2452                                      ‫سليم.‬   \n",
              "2453      عايزة تاخدي وقتك وتفكري، براحتك طبعاً.    \n",
              "2454                                     إتفضلي.‬   \n",
              "2455              ستة وعشرين وخمسة، واحد وتلاتين.   \n",
              "\n",
              "                                           english_Text  \n",
              "0             As usual, Refaat can’t play hide-and-seek  \n",
              "1     We have to make sure we have permission before...  \n",
              "2                                You're probably right.  \n",
              "3                       But you have to buy new shirts.  \n",
              "4                                             Thank you  \n",
              "...                                                 ...  \n",
              "2451                         I already know everything.  \n",
              "2452                                              Salim  \n",
              "2453  If you'd take some time to think about it, tha...  \n",
              "2454                                          Step out.  \n",
              "2455               Twenty-six and five make thirty-one.  \n",
              "\n",
              "[2456 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7812cbb7-7d35-4db0-96d1-464a2fe1c455\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>egyption_Text</th>\n",
              "      <th>english_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>كالعادة رفعت ما بيعرفش يلعب استغماية</td>\n",
              "      <td>As usual, Refaat can’t play hide-and-seek</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>مانقدروش نخشوا الكهف قبل ما نستأذنوا العساس</td>\n",
              "      <td>We have to make sure we have permission before...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>‫صح، إنتي عندك حق.‬</td>\n",
              "      <td>You're probably right.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>بس أنت لازم تشتري قمصان جديدة، هه؟</td>\n",
              "      <td>But you have to buy new shirts.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>اهلا بحضرتك</td>\n",
              "      <td>Thank you</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2451</th>\n",
              "      <td>ما أنا عارفة كل حاجة.</td>\n",
              "      <td>I already know everything.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2452</th>\n",
              "      <td>‫سليم.‬</td>\n",
              "      <td>Salim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2453</th>\n",
              "      <td>عايزة تاخدي وقتك وتفكري، براحتك طبعاً.</td>\n",
              "      <td>If you'd take some time to think about it, tha...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2454</th>\n",
              "      <td>إتفضلي.‬</td>\n",
              "      <td>Step out.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2455</th>\n",
              "      <td>ستة وعشرين وخمسة، واحد وتلاتين.</td>\n",
              "      <td>Twenty-six and five make thirty-one.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2456 rows × 2 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7812cbb7-7d35-4db0-96d1-464a2fe1c455')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7812cbb7-7d35-4db0-96d1-464a2fe1c455 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7812cbb7-7d35-4db0-96d1-464a2fe1c455');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-8e81ad60-611f-4916-be16-06becd54292d\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8e81ad60-611f-4916-be16-06becd54292d')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-8e81ad60-611f-4916-be16-06becd54292d button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_4a1164d9-86ab-4920-aca8-f03b1ec09a01\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_test')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_4a1164d9-86ab-4920-aca8-f03b1ec09a01 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_test');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_test",
              "summary": "{\n  \"name\": \"df_test\",\n  \"rows\": 2456,\n  \"fields\": [\n    {\n      \"column\": \"egyption_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2324,\n        \"samples\": [\n          \"\\u062f\\u064a \\u0645\\u064a\\u0632\\u062a\\u0647\\u0645 \\u0627\\u0644\\u0648\\u062d\\u064a\\u062f\\u0629 \",\n          \"\\u0641\\u064a \\u062d\\u062f \\u0643\\u062a\\u0628 \\u0642\\u0627\\u0644: \\\"\\u0646\\u0641\\u0633\\u064a \\u0628\\u0627\\u0628\\u0627 \\u064a\\u0628\\u0637\\u0644 \\u064a\\u0642\\u0648\\u0644\\u064a \\u0623\\u0639\\u0645\\u0644 \\u0625\\u064a\\u0647.\\\"\",\n          \"\\u062d\\u0627\\u0636\\u0631 \\u064a\\u0627 \\u0641\\u0646\\u062f\\u0645\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"english_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2351,\n        \"samples\": [\n          \"She wore a white dress and looked like a demon.\",\n          \"Also, I forgot to tell you.\",\n          \"Blessed by Amun and Maat, 'til destiny reunites with my beloved, all evil in the world shall end.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "BWB5A9rQ-Wa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import string\n",
        "\n",
        "def preprocess_arabic(text):\n",
        "    if pd.isna(text): return \"\"\n",
        "\n",
        "    text = re.sub(r'[\\u0617-\\u061A\\u064B-\\u0652]', '', text)\n",
        "\n",
        "    text = re.sub(r'[^\\u0600-\\u06FF\\s]', '', text)\n",
        "\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    arabic_punctuations = r'''`÷×؛<>_()*&^%][ـ،/:\"؟.,'{}~¦+|!”…“–ـ'''\n",
        "    english_punctuations = string.punctuation\n",
        "    all_punctuations = arabic_punctuations + english_punctuations\n",
        "    text = re.sub(f\"[{re.escape(all_punctuations)}]\", \"\", text)\n",
        "\n",
        "    text = text.replace(\"أ\", \"ا\").replace(\"إ\", \"ا\").replace(\"آ\", \"ا\")\n",
        "    text = text.replace(\"ى\", \"ي\").replace(\"ئ\", \"ي\").replace(\"ؤ\", \"و\")\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "MI7ByRWvpKGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_english(text):\n",
        "    if pd.isna(text): return \"\"\n",
        "\n",
        "    text = text.lower()\n",
        "\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "\n",
        "    text = re.sub(r'\\d+', '', text)\n",
        "\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "-m3dbgzdpJ_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_translation_data(df, arabic_col='arabic', english_col='english'):\n",
        "    df[arabic_col] = df[arabic_col].apply(preprocess_arabic)\n",
        "    df[english_col] = df[english_col].apply(preprocess_english)\n",
        "    df.dropna(inplace=True)\n",
        "    df = df[(df[arabic_col] != \"\") & (df[english_col] != \"\")]\n",
        "    return df"
      ],
      "metadata": {
        "id": "BCwnDBhOpJ81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11dcf356"
      },
      "source": [
        "# Save the text data to files for SentencePiece training\n",
        "with open('egyptian.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in df_train['egyption_Text']:\n",
        "        f.write(text + '\\n')\n",
        "\n",
        "with open('english.txt', 'w', encoding='utf-8') as f:\n",
        "    for text in df_train['english_Text']:\n",
        "        f.write(text + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sentencepiece as spm\n",
        "\n",
        "# Train SentencePiece for Arabic\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input='egyptian.txt',\n",
        "    model_prefix='spm_arabic',\n",
        "    vocab_size=8000,\n",
        "    character_coverage=1.0\n",
        ")\n",
        "\n",
        "# Train SentencePiece for English\n",
        "spm.SentencePieceTrainer.train(\n",
        "    input='english.txt',\n",
        "    model_prefix='spm_english',\n",
        "    vocab_size=6447,  # Changed vocabulary size to the maximum allowed\n",
        "    character_coverage=1.0\n",
        ")\n",
        "\n",
        "# Load models\n",
        "sp_ar = spm.SentencePieceProcessor()\n",
        "sp_ar.load(\"spm_arabic.model\")\n",
        "\n",
        "sp_en = spm.SentencePieceProcessor()\n",
        "sp_en.load(\"spm_english.model\")\n",
        "\n",
        "# Encode sentences using subwords\n",
        "df_train['arabic_encoded'] = df_train['egyption_Text'].apply(lambda x: [sp_ar.bos_id()] + sp_ar.encode(x, out_type=int) + [sp_ar.eos_id()])\n",
        "df_train['english_encoded'] = df_train['english_Text'].apply(lambda x: [sp_en.bos_id()] + sp_en.encode(x, out_type=int) + [sp_en.eos_id()])\n",
        "\n",
        "df_test['arabic_encoded'] = df_test['egyption_Text'].apply(lambda x: [sp_ar.bos_id()] + sp_ar.encode(x, out_type=int) + [sp_ar.eos_id()])\n",
        "df_test['english_encoded'] = df_test['english_Text'].apply(lambda x: [sp_en.bos_id()] + sp_en.encode(x, out_type=int) + [sp_en.eos_id()])\n",
        "\n",
        "# Update vocab sizes\n",
        "SRC_VOCAB_SIZE = sp_ar.get_piece_size()\n",
        "TGT_VOCAB_SIZE = sp_en.get_piece_size()"
      ],
      "metadata": {
        "id": "zzt9uOBKxExr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = clean_translation_data(df_train, arabic_col='egyption_Text', english_col='english_Text')\n",
        "df_test = clean_translation_data(df_test, arabic_col='egyption_Text', english_col='english_Text')\n"
      ],
      "metadata": {
        "id": "d6ojYOiMpVv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display(df_train.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "id": "xDSxUgB-pYeG",
        "outputId": "eef7ab5e-7e70-4f6f-c262-dbb3c067e703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                                       egyption_Text  \\\n",
              "0                                            يلا فين   \n",
              "1                           حضرتك تقصد شخص عايش يعني   \n",
              "2             وجه واحد اشجع مني شوية وسبقني واتجوزها   \n",
              "3                              انا محتاج اتكلم معاكي   \n",
              "4  الامير الصغير ماقدرش يوصل لفايدة عامود نور ورا...   \n",
              "\n",
              "                                        english_Text  \\\n",
              "0                                           go where   \n",
              "1                    do you mean like someone living   \n",
              "2    then someone came along and married her instead   \n",
              "3                                    we need to talk   \n",
              "4  the little prince was not able to reach any ex...   \n",
              "\n",
              "                                      arabic_encoded  \\\n",
              "0                                   [1, 184, 102, 2]   \n",
              "1               [1, 119, 75, 2459, 1398, 434, 52, 2]   \n",
              "2  [1, 1580, 117, 36, 2691, 349, 81, 6682, 39, 9,...   \n",
              "3                           [1, 4, 218, 416, 332, 2]   \n",
              "4  [1, 143, 122, 1392, 22, 1989, 80, 5017, 6, 466...   \n",
              "\n",
              "                                     english_encoded  \n",
              "0                                    [1, 66, 109, 2]  \n",
              "1                   [1, 36, 5, 148, 49, 240, 794, 2]  \n",
              "2         [1, 72, 240, 154, 757, 7, 471, 32, 647, 2]  \n",
              "3                            [1, 35, 129, 6, 269, 2]  \n",
              "4  [1, 3, 93, 170, 18, 21, 589, 6, 726, 166, 1985...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-50887d2f-e5f2-4e07-a32a-b43c2e25a766\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>egyption_Text</th>\n",
              "      <th>english_Text</th>\n",
              "      <th>arabic_encoded</th>\n",
              "      <th>english_encoded</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>يلا فين</td>\n",
              "      <td>go where</td>\n",
              "      <td>[1, 184, 102, 2]</td>\n",
              "      <td>[1, 66, 109, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>حضرتك تقصد شخص عايش يعني</td>\n",
              "      <td>do you mean like someone living</td>\n",
              "      <td>[1, 119, 75, 2459, 1398, 434, 52, 2]</td>\n",
              "      <td>[1, 36, 5, 148, 49, 240, 794, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>وجه واحد اشجع مني شوية وسبقني واتجوزها</td>\n",
              "      <td>then someone came along and married her instead</td>\n",
              "      <td>[1, 1580, 117, 36, 2691, 349, 81, 6682, 39, 9,...</td>\n",
              "      <td>[1, 72, 240, 154, 757, 7, 471, 32, 647, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>انا محتاج اتكلم معاكي</td>\n",
              "      <td>we need to talk</td>\n",
              "      <td>[1, 4, 218, 416, 332, 2]</td>\n",
              "      <td>[1, 35, 129, 6, 269, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>الامير الصغير ماقدرش يوصل لفايدة عامود نور ورا...</td>\n",
              "      <td>the little prince was not able to reach any ex...</td>\n",
              "      <td>[1, 143, 122, 1392, 22, 1989, 80, 5017, 6, 466...</td>\n",
              "      <td>[1, 3, 93, 170, 18, 21, 589, 6, 726, 166, 1985...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50887d2f-e5f2-4e07-a32a-b43c2e25a766')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-50887d2f-e5f2-4e07-a32a-b43c2e25a766 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-50887d2f-e5f2-4e07-a32a-b43c2e25a766');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-3cb50374-525c-4f19-9a19-5f19b0f8e5a4\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3cb50374-525c-4f19-9a19-5f19b0f8e5a4')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-3cb50374-525c-4f19-9a19-5f19b0f8e5a4 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(df_train\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"egyption_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"\\u062d\\u0636\\u0631\\u062a\\u0643 \\u062a\\u0642\\u0635\\u062f \\u0634\\u062e\\u0635 \\u0639\\u0627\\u064a\\u0634 \\u064a\\u0639\\u0646\\u064a\",\n          \"\\u0627\\u0644\\u0627\\u0645\\u064a\\u0631 \\u0627\\u0644\\u0635\\u063a\\u064a\\u0631 \\u0645\\u0627\\u0642\\u062f\\u0631\\u0634 \\u064a\\u0648\\u0635\\u0644 \\u0644\\u0641\\u0627\\u064a\\u062f\\u0629 \\u0639\\u0627\\u0645\\u0648\\u062f \\u0646\\u0648\\u0631 \\u0648\\u0631\\u0627\\u062c\\u0644 \\u0634\\u063a\\u0644\\u062a\\u0647 \\u0627\\u0646\\u0647 \\u064a\\u0646\\u0648\\u0631\\u0647 \\u0639\\u0644\\u064a \\u0643\\u0648\\u0643\\u0628 \\u0645\\u0646 \\u063a\\u064a\\u0631 \\u0628\\u064a\\u0648\\u062a \\u0648\\u0644\\u0627 \\u0633\\u0643\\u0627\\u0646 \\u0641\\u064a \\u062d\\u062a\\u0629 \\u0643\\u062f\\u0647 \\u0641\\u064a \\u0627\\u0644\\u0633\\u0645\\u0627\",\n          \"\\u0648\\u062c\\u0647 \\u0648\\u0627\\u062d\\u062f \\u0627\\u0634\\u062c\\u0639 \\u0645\\u0646\\u064a \\u0634\\u0648\\u064a\\u0629 \\u0648\\u0633\\u0628\\u0642\\u0646\\u064a \\u0648\\u0627\\u062a\\u062c\\u0648\\u0632\\u0647\\u0627\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"english_Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"do you mean like someone living\",\n          \"the little prince was not able to reach any explanation of the use of a street lamp and a lamplighter somewhere in the heavens on a planet which had no people and not one house\",\n          \"then someone came along and married her instead\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"arabic_encoded\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"english_encoded\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['egyption_Text'] = df_train['egyption_Text'].apply(preprocess_arabic)\n",
        "df_train['english_Text'] = df_train['english_Text'].apply(preprocess_english)\n",
        "\n",
        "df_test['egyption_Text'] = df_test['egyption_Text'].apply(preprocess_arabic)\n",
        "df_test['english_Text'] = df_test['english_Text'].apply(preprocess_english)\n",
        "\n",
        "df_train = clean_translation_data(df_train, arabic_col='egyption_Text', english_col='english_Text')\n",
        "df_test = clean_translation_data(df_test, arabic_col='egyption_Text', english_col='english_Text')"
      ],
      "metadata": {
        "id": "avlXJO3r-iVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_vocab(sentences, min_freq=1):\n",
        "    from collections import Counter\n",
        "\n",
        "    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n",
        "    word_freq = Counter()\n",
        "\n",
        "    for sent in sentences:\n",
        "        word_freq.update(sent.split())\n",
        "\n",
        "    for word, freq in word_freq.items():\n",
        "        if freq >= min_freq:\n",
        "            vocab[word] = len(vocab)\n",
        "\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "8Tk74DHz-iRT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arabic_vocab = build_vocab(df_train['egyption_Text'])\n",
        "english_vocab = build_vocab(df_train['english_Text'])"
      ],
      "metadata": {
        "id": "ZVjHAIq8-iQP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_sentence(sentence, vocab, add_sos_eos=True):\n",
        "    tokens = sentence.split()\n",
        "    ids = [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
        "    if add_sos_eos:\n",
        "        ids = [vocab['<sos>']] + ids + [vocab['<eos>']]\n",
        "    return ids"
      ],
      "metadata": {
        "id": "WhSS1W7i-19u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train['arabic_encoded'] = df_train['egyption_Text'].apply(lambda x: encode_sentence(x, arabic_vocab))\n",
        "df_train['english_encoded'] = df_train['english_Text'].apply(lambda x: encode_sentence(x, english_vocab))\n",
        "\n",
        "df_test['arabic_encoded'] = df_test['egyption_Text'].apply(lambda x: encode_sentence(x, arabic_vocab))\n",
        "df_test['english_encoded'] = df_test['english_Text'].apply(lambda x: encode_sentence(x, english_vocab))"
      ],
      "metadata": {
        "id": "GXbjlJ9l-15k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pad_sequence(seq, max_len, pad_idx):\n",
        "    return seq + [pad_idx] * (max_len - len(seq))\n"
      ],
      "metadata": {
        "id": "d2PSfic--13U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, src_data, tgt_data, pad_idx=0):\n",
        "        self.src_data = src_data\n",
        "        self.tgt_data = tgt_data\n",
        "        self.pad_idx = pad_idx\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.src_data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src = self.src_data[idx]\n",
        "        tgt = self.tgt_data[idx]\n",
        "        return torch.tensor(src), torch.tensor(tgt)\n"
      ],
      "metadata": {
        "id": "_ZHYS3K-_EPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch, pad_idx=0):\n",
        "    src_batch, tgt_batch = zip(*batch)\n",
        "\n",
        "    src_max_len = max(len(x) for x in src_batch)\n",
        "    tgt_max_len = max(len(y) for y in tgt_batch)\n",
        "\n",
        "    src_padded = torch.stack([torch.tensor(pad_sequence(x.tolist(), src_max_len, pad_idx)) for x in src_batch])\n",
        "    tgt_padded = torch.stack([torch.tensor(pad_sequence(y.tolist(), tgt_max_len, pad_idx)) for y in tgt_batch])\n",
        "\n",
        "    return src_padded, tgt_padded\n"
      ],
      "metadata": {
        "id": "S5BgdYas_ELz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "pad_idx = 0  # assuming <pad> is index 0 in both vocabs\n",
        "\n",
        "train_dataset = TranslationDataset(\n",
        "    df_train['arabic_encoded'].tolist(),\n",
        "    df_train['english_encoded'].tolist(),\n",
        "    pad_idx=pad_idx\n",
        ")\n",
        "\n",
        "test_dataset = TranslationDataset(\n",
        "    df_test['arabic_encoded'].tolist(),\n",
        "    df_test['english_encoded'].tolist(),\n",
        "    pad_idx=pad_idx\n",
        ")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=lambda x: collate_fn(x, pad_idx))\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=lambda x: collate_fn(x, pad_idx))\n"
      ],
      "metadata": {
        "id": "hqNiteZM_EIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import math\n",
        "\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len=5000):\n",
        "        super().__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "\n",
        "        position = torch.arange(0, max_len).unsqueeze(1).float()\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "\n",
        "        self.pe = pe.unsqueeze(0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)].to(x.device)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "Gi37oafE_QFq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super().__init__()\n",
        "        assert d_model % num_heads == 0\n",
        "\n",
        "        self.d_k = d_model // num_heads\n",
        "        self.num_heads = num_heads\n",
        "\n",
        "        self.q_linear = nn.Linear(d_model, d_model)\n",
        "        self.k_linear = nn.Linear(d_model, d_model)\n",
        "        self.v_linear = nn.Linear(d_model, d_model)\n",
        "        self.out = nn.Linear(d_model, d_model)\n",
        "\n",
        "    def forward(self, q, k, v, mask=None):\n",
        "        B_q, T_q, D_q = q.shape\n",
        "        B_k, T_k, D_k = k.shape\n",
        "        B_v, T_v, D_v = v.shape\n",
        "\n",
        "        H = self.num_heads\n",
        "\n",
        "        # Linear transformations and reshape for multi-head attention\n",
        "        q = self.q_linear(q).view(B_q, T_q, H, self.d_k).transpose(1, 2)  # (B, H, T_q, d_k)\n",
        "        k = self.k_linear(k).view(B_k, T_k, H, self.d_k).transpose(1, 2)  # (B, H, T_k, d_k)\n",
        "        v = self.v_linear(v).view(B_v, T_v, H, self.d_k).transpose(1, 2)  # (B, H, T_v, d_k)\n",
        "\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
        "\n",
        "        if mask is not None:\n",
        "            # Ensure mask is broadcastable\n",
        "            if mask.ndim == 3: # Mask with shape (B, T_q, T_k)\n",
        "                 mask = mask.unsqueeze(1) # (B, 1, T_q, T_k)\n",
        "            elif mask.ndim == 2: # Mask with shape (T_q, T_k)\n",
        "                 mask = mask.unsqueeze(0).unsqueeze(1) # (1, 1, T_q, T_k)\n",
        "            elif mask.ndim == 4: # Mask with shape (B, H, T_q, T_k) or (1, 1, T_q, T_k)\n",
        "                 pass # Assume mask is already in the correct broadcastable shape\n",
        "            else:\n",
        "                 raise ValueError(f\"Unsupported mask dimensions: {mask.ndim}\")\n",
        "\n",
        "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
        "\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "        out = torch.matmul(attn, v)  # (B, H, T_q, d_k) - output sequence length matches query\n",
        "\n",
        "        out = out.transpose(1, 2).contiguous().view(B_q, T_q, self.num_heads * self.d_k)\n",
        "        return self.out(out)"
      ],
      "metadata": {
        "id": "wkC5hQyT_QB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, d_model, d_ff=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(d_model, d_ff),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(d_ff, d_model),\n",
        "            nn.Dropout(dropout)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n"
      ],
      "metadata": {
        "id": "QMHyz9Nk_V8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        x2 = self.attn(x, x, x, mask)\n",
        "        x = self.norm1(x + x2)\n",
        "        x2 = self.ff(x)\n",
        "        x = self.norm2(x + x2)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "nzduXGM8_YCS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(nn.Module):\n",
        "    def __init__(self, d_model, num_heads, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ff = FeedForward(d_model, d_ff, dropout)\n",
        "        self.norm1 = nn.LayerNorm(d_model)\n",
        "        self.norm2 = nn.LayerNorm(d_model)\n",
        "        self.norm3 = nn.LayerNorm(d_model)\n",
        "\n",
        "    def forward(self, x, enc_out, tgt_mask, src_mask):\n",
        "        x2 = self.self_attn(x, x, x, tgt_mask)\n",
        "        x = self.norm1(x + x2)\n",
        "        x2 = self.cross_attn(x, enc_out, enc_out, src_mask)\n",
        "        x = self.norm2(x + x2)\n",
        "        x2 = self.ff(x)\n",
        "        x = self.norm3(x + x2)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "D_3Y-Onm_X-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, num_heads, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoding(d_model)\n",
        "        self.layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(N)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        x = self.embed(src)\n",
        "        x = self.pe(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, src_mask)\n",
        "\n",
        "        return x\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, vocab_size, d_model, N, num_heads, d_ff, dropout):\n",
        "        super().__init__()\n",
        "        self.embed = nn.Embedding(vocab_size, d_model)\n",
        "        self.pe = PositionalEncoding(d_model)\n",
        "        self.layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(N)])\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "    def forward(self, tgt, enc_out, tgt_mask, src_mask):\n",
        "        x = self.embed(tgt)\n",
        "        x = self.pe(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, enc_out, tgt_mask, src_mask)\n",
        "\n",
        "        return self.out(x)\n"
      ],
      "metadata": {
        "id": "xnLBzVlS_X6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(nn.Module):\n",
        "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model=512, N=4, num_heads=8, d_ff=2048, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.encoder = Encoder(src_vocab_size, d_model, N, num_heads, d_ff, dropout)\n",
        "        self.decoder = Decoder(tgt_vocab_size, d_model, N, num_heads, d_ff, dropout)\n",
        "\n",
        "    def make_pad_mask(self, seq, pad_idx):\n",
        "        return (seq != pad_idx).unsqueeze(1).unsqueeze(2)  # (B, 1, 1, T)\n",
        "\n",
        "    def make_subsequent_mask(self, size):\n",
        "        mask = torch.tril(torch.ones((size, size), dtype=torch.bool))\n",
        "        return mask.unsqueeze(0).unsqueeze(1)  # (1, 1, T, T)\n",
        "\n",
        "    def forward(self, src, tgt, src_pad_idx, tgt_pad_idx):\n",
        "        src_mask = self.make_pad_mask(src, src_pad_idx).to(src.device)\n",
        "        tgt_mask = self.make_pad_mask(tgt, tgt_pad_idx).to(tgt.device) & \\\n",
        "                   self.make_subsequent_mask(tgt.size(1)).to(tgt.device)\n",
        "\n",
        "        enc_out = self.encoder(src, src_mask)\n",
        "        out = self.decoder(tgt, enc_out, tgt_mask, src_mask)\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "73L42pJU_eZ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import time\n"
      ],
      "metadata": {
        "id": "I59_91-4_mPq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_fn(pred, target, pad_idx):\n",
        "    pred = pred.reshape(-1, pred.size(-1))\n",
        "    target = target.reshape(-1)\n",
        "    loss = F.cross_entropy(pred, target, ignore_index=pad_idx)\n",
        "    return loss"
      ],
      "metadata": {
        "id": "LWL4QaeQ_gD9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_epoch(model, dataloader, optimizer, pad_idx, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for src, tgt in dataloader:\n",
        "        src = src.to(device)\n",
        "        tgt = tgt.to(device)\n",
        "\n",
        "        # Shift input and target for teacher forcing\n",
        "        tgt_input = tgt[:, :-1]\n",
        "        tgt_output = tgt[:, 1:]\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(src, tgt_input, pad_idx, pad_idx)\n",
        "\n",
        "        loss = loss_fn(output, tgt_output, pad_idx)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "Kb_sNA_s_gA9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader, pad_idx, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for src, tgt in dataloader:\n",
        "            src = src.to(device)\n",
        "            tgt = tgt.to(device)\n",
        "\n",
        "            tgt_input = tgt[:, :-1]\n",
        "            tgt_output = tgt[:, 1:]\n",
        "\n",
        "            output = model(src, tgt_input, pad_idx, pad_idx)\n",
        "            loss = loss_fn(output, tgt_output, pad_idx)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    return total_loss / len(dataloader)\n"
      ],
      "metadata": {
        "id": "evLYH6Vs_f7n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(torch.__version__)\n",
        "print(torch.__file__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVDEWlR-iz0p",
        "outputId": "92ac5937-2925-4f46-f233-c6ee11907883"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n",
            "/usr/local/lib/python3.11/dist-packages/torch/__init__.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade torch torchvision torchaudio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fxHeal7zi-Dq",
        "outputId": "038c2198-a412-4504-d7a6-635142b374cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Collecting torch\n",
            "  Using cached torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.16.0)\n",
            "Collecting torchvision\n",
            "  Using cached torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.1.0)\n",
            "Collecting torchaudio\n",
            "  Using cached torchaudio-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.14.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch)\n",
            "  Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cublas-cu12==12.8.4.1 (from torch)\n",
            "  Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch)\n",
            "  Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.9.90 (from torch)\n",
            "  Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch)\n",
            "  Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.5.8.93 (from torch)\n",
            "  Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.11/dist-packages (from torch) (0.7.1)\n",
            "Collecting nvidia-nccl-cu12==2.27.3 (from torch)\n",
            "  Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.8.90 (from torch)\n",
            "  Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.11/dist-packages (from torch) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1.3)\n",
            "Collecting triton==3.4.0 (from torch)\n",
            "  Using cached triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: setuptools>=40.8.0 in /usr/local/lib/python3.11/dist-packages (from triton==3.4.0->torch) (75.2.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Using cached torch-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (888.1 MB)\n",
            "Using cached nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
            "Using cached nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
            "Using cached nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
            "Using cached nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
            "Using cached nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
            "Using cached nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
            "Using cached nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
            "Using cached nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
            "Using cached nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
            "Using cached nvidia_nccl_cu12-2.27.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.4 MB)\n",
            "Using cached nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
            "Using cached triton-3.4.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (155.5 MB)\n",
            "Using cached torchvision-0.23.0-cp311-cp311-manylinux_2_28_x86_64.whl (8.6 MB)\n",
            "Using cached torchaudio-2.8.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.0 MB)\n",
            "Installing collected packages: triton, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.1.0\n",
            "    Uninstalling triton-2.1.0:\n",
            "      Successfully uninstalled triton-2.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.1.105\n",
            "    Uninstalling nvidia-nvtx-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.18.1\n",
            "    Uninstalling nvidia-nccl-cu12-2.18.1:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.18.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.1.0.106\n",
            "    Uninstalling nvidia-cusparse-cu12-12.1.0.106:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.1.0.106\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.2.106\n",
            "    Uninstalling nvidia-curand-cu12-10.3.2.106:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.2.106\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.0.2.54\n",
            "    Uninstalling nvidia-cufft-cu12-11.0.2.54:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.0.2.54\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.1.105\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.1.105:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.1.105\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.1.3.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.1.3.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.1.3.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.4.5.107\n",
            "    Uninstalling nvidia-cusolver-cu12-11.4.5.107:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.4.5.107\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 8.9.2.26\n",
            "    Uninstalling nvidia-cudnn-cu12-8.9.2.26:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-8.9.2.26\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.1.0\n",
            "    Uninstalling torch-2.1.0:\n",
            "      Successfully uninstalled torch-2.1.0\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.16.0\n",
            "    Uninstalling torchvision-0.16.0:\n",
            "      Successfully uninstalled torchvision-0.16.0\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.1.0\n",
            "    Uninstalling torchaudio-2.1.0:\n",
            "      Successfully uninstalled torchaudio-2.1.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.8.0 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.8.0 which is incompatible.\n",
            "fastai 2.7.19 requires torch<2.7,>=1.10, but you have torch 2.8.0 which is incompatible.\n",
            "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-nccl-cu12-2.27.3 nvidia-nvtx-cu12-12.8.90 torch-2.8.0 torchaudio-2.8.0 torchvision-0.23.0 triton-3.4.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "4f697c8d3e1d4b3e889ed7dddbdbf159"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall torch torchvision torchaudio -y\n",
        "!pip cache purge\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "bJGaVnxWlO_e",
        "outputId": "0c576e9d-786e-483c-90e8-b505f89f314a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: torch 2.8.0\n",
            "Uninstalling torch-2.8.0:\n",
            "  Successfully uninstalled torch-2.8.0\n",
            "Found existing installation: torchvision 0.23.0\n",
            "Uninstalling torchvision-0.23.0:\n",
            "  Successfully uninstalled torchvision-0.23.0\n",
            "Found existing installation: torchaudio 2.8.0\n",
            "Uninstalling torchaudio-2.8.0:\n",
            "  Successfully uninstalled torchaudio-2.8.0\n",
            "Files removed: 192\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
            "Collecting torch\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (780.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m780.5/780.5 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp311-cp311-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m103.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp311-cp311-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m96.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/cu121/nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.5/209.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sympy==1.13.1 (from torch)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m113.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.11/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.8.93)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nccl-cu12, nvidia-cusparse-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusolver-cu12, nvidia-cudnn-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.4.0\n",
            "    Uninstalling triton-3.4.0:\n",
            "      Successfully uninstalled triton-3.4.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.8.90\n",
            "    Uninstalling nvidia-nvtx-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.3\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.3:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.3\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.9.90\n",
            "    Uninstalling nvidia-curand-cu12-10.3.9.90:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.93\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.93:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.93\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.8.90\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.8.90:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.90\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchdata 0.7.0 requires torch==2.1.0, but you have torch 2.5.1+cu121 which is incompatible.\n",
            "torchtext 0.16.0 requires torch==2.1.0, but you have torch 2.5.1+cu121 which is incompatible.\n",
            "torchtune 0.6.1 requires torchdata==0.11.0, but you have torchdata 0.7.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.21.5 nvidia-nvtx-cu12-12.1.105 sympy-1.13.1 torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121 triton-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sympy",
                  "torch",
                  "torchgen"
                ]
              },
              "id": "3b0c4ccfa9874a82ad585ba11c9c7179"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(hasattr(torch, \"uint64\"))  # should be True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IiSx4d3LjB-s",
        "outputId": "6e11229d-dc49-43c5-87ea-3979f5255d33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "SRC_VOCAB_SIZE = len(arabic_vocab)\n",
        "TGT_VOCAB_SIZE = len(english_vocab)\n",
        "PAD_IDX = 0\n",
        "\n",
        "model = Transformer(SRC_VOCAB_SIZE, TGT_VOCAB_SIZE).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
      ],
      "metadata": {
        "id": "y3ZSV6Z7_sCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start_time = time.time()\n",
        "\n",
        "    train_loss = train_epoch(model, train_loader, optimizer, PAD_IDX, device)\n",
        "    val_loss = evaluate(model, test_loader, PAD_IDX, device)\n",
        "\n",
        "    end_time = time.time()\n",
        "    epoch_mins, epoch_secs = divmod(int(end_time - start_time), 60)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS} | Time: {epoch_mins}m {epoch_secs}s\")\n",
        "    print(f\"\\tTrain Loss: {train_loss:.4f}\")\n",
        "    print(f\"\\tVal Loss:   {val_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "tsa_kL9q_r-w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8e67da1-3d2f-4115-9b34-22641d3ff205"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20 | Time: 0m 49s\n",
            "\tTrain Loss: 5.5261\n",
            "\tVal Loss:   4.9384\n",
            "Epoch 2/20 | Time: 0m 49s\n",
            "\tTrain Loss: 4.5996\n",
            "\tVal Loss:   4.5413\n",
            "Epoch 3/20 | Time: 0m 50s\n",
            "\tTrain Loss: 4.1310\n",
            "\tVal Loss:   4.3524\n",
            "Epoch 4/20 | Time: 0m 48s\n",
            "\tTrain Loss: 3.7158\n",
            "\tVal Loss:   4.2037\n",
            "Epoch 5/20 | Time: 0m 49s\n",
            "\tTrain Loss: 3.3054\n",
            "\tVal Loss:   4.1209\n",
            "Epoch 6/20 | Time: 0m 49s\n",
            "\tTrain Loss: 2.8934\n",
            "\tVal Loss:   4.1139\n",
            "Epoch 7/20 | Time: 0m 49s\n",
            "\tTrain Loss: 2.4816\n",
            "\tVal Loss:   4.1051\n",
            "Epoch 8/20 | Time: 0m 49s\n",
            "\tTrain Loss: 2.0899\n",
            "\tVal Loss:   4.1579\n",
            "Epoch 9/20 | Time: 0m 48s\n",
            "\tTrain Loss: 1.7152\n",
            "\tVal Loss:   4.2533\n",
            "Epoch 10/20 | Time: 0m 49s\n",
            "\tTrain Loss: 1.3868\n",
            "\tVal Loss:   4.3528\n",
            "Epoch 11/20 | Time: 0m 49s\n",
            "\tTrain Loss: 1.0956\n",
            "\tVal Loss:   4.4715\n",
            "Epoch 12/20 | Time: 0m 48s\n",
            "\tTrain Loss: 0.8571\n",
            "\tVal Loss:   4.5813\n",
            "Epoch 13/20 | Time: 0m 49s\n",
            "\tTrain Loss: 0.6743\n",
            "\tVal Loss:   4.6859\n",
            "Epoch 14/20 | Time: 0m 49s\n",
            "\tTrain Loss: 0.5347\n",
            "\tVal Loss:   4.7837\n",
            "Epoch 15/20 | Time: 0m 48s\n",
            "\tTrain Loss: 0.4387\n",
            "\tVal Loss:   4.9231\n",
            "Epoch 16/20 | Time: 0m 48s\n",
            "\tTrain Loss: 0.3772\n",
            "\tVal Loss:   5.0078\n",
            "Epoch 17/20 | Time: 0m 48s\n",
            "\tTrain Loss: 0.3379\n",
            "\tVal Loss:   5.0729\n",
            "Epoch 18/20 | Time: 0m 49s\n",
            "\tTrain Loss: 0.3143\n",
            "\tVal Loss:   5.1353\n",
            "Epoch 19/20 | Time: 0m 49s\n",
            "\tTrain Loss: 0.2888\n",
            "\tVal Loss:   5.2045\n",
            "Epoch 20/20 | Time: 0m 49s\n",
            "\tTrain Loss: 0.2724\n",
            "\tVal Loss:   5.2486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(model.state_dict(), \"transformer_nmt.pt\")\n"
      ],
      "metadata": {
        "id": "32oK9vTr_r7l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(\"transformer_nmt.pt\"))\n",
        "model.to(device)\n",
        "model.eval()\n"
      ],
      "metadata": {
        "id": "gmtOXeDx_53M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aefcfed3-7d76-458e-8f66-98651a6af2fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-222799761.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(\"transformer_nmt.pt\"))\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Transformer(\n",
              "  (encoder): Encoder(\n",
              "    (embed): Embedding(19382, 512)\n",
              "    (pe): PositionalEncoding()\n",
              "    (layers): ModuleList(\n",
              "      (0-3): 4 x EncoderLayer(\n",
              "        (attn): MultiHeadAttention(\n",
              "          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (net): Sequential(\n",
              "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (1): ReLU()\n",
              "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (3): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (decoder): Decoder(\n",
              "    (embed): Embedding(8612, 512)\n",
              "    (pe): PositionalEncoding()\n",
              "    (layers): ModuleList(\n",
              "      (0-3): 4 x DecoderLayer(\n",
              "        (self_attn): MultiHeadAttention(\n",
              "          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (cross_attn): MultiHeadAttention(\n",
              "          (q_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (k_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (v_linear): Linear(in_features=512, out_features=512, bias=True)\n",
              "          (out): Linear(in_features=512, out_features=512, bias=True)\n",
              "        )\n",
              "        (ff): FeedForward(\n",
              "          (net): Sequential(\n",
              "            (0): Linear(in_features=512, out_features=2048, bias=True)\n",
              "            (1): ReLU()\n",
              "            (2): Linear(in_features=2048, out_features=512, bias=True)\n",
              "            (3): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "        (norm3): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out): Linear(in_features=512, out_features=8612, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_input(sentence, vocab):\n",
        "    sentence = preprocess_arabic(sentence)\n",
        "    tokens = sentence.split()\n",
        "    ids = [vocab.get(token, vocab['<unk>']) for token in tokens]\n",
        "    return torch.tensor([[vocab['<sos>']] + ids + [vocab['<eos>']]], dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "WyJiDhrP_5yT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def greedy_decode(model, src_sentence, src_vocab, tgt_vocab, max_len=50, device='cpu'):\n",
        "    model.eval()\n",
        "    idx2word = {idx: word for word, idx in tgt_vocab.items()}\n",
        "\n",
        "    src = encode_input(src_sentence, src_vocab).to(device)\n",
        "    src_mask = model.make_pad_mask(src, pad_idx=0).to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        enc_out = model.encoder(src, src_mask)\n",
        "\n",
        "    tgt_indices = [tgt_vocab['<sos>']]\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        tgt_tensor = torch.tensor([tgt_indices], dtype=torch.long).to(device)\n",
        "        tgt_mask = model.make_pad_mask(tgt_tensor, pad_idx=0).to(device) & model.make_subsequent_mask(tgt_tensor.size(1)).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model.decoder(tgt_tensor, enc_out, tgt_mask, src_mask)\n",
        "            next_token = output[:, -1, :].argmax(dim=-1).item()\n",
        "\n",
        "        if next_token == tgt_vocab['<eos>']:\n",
        "            break\n",
        "\n",
        "        tgt_indices.append(next_token)\n",
        "\n",
        "    words = [idx2word[idx] for idx in tgt_indices[1:] if idx not in (tgt_vocab['<eos>'], tgt_vocab['<pad>'])]\n",
        "    return ' '.join(words)\n"
      ],
      "metadata": {
        "id": "DTAWXoaYGrM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install gradio --quiet"
      ],
      "metadata": {
        "id": "eTwbprduH26D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "def translate_arabic_sentence(sentence):\n",
        "    try:\n",
        "        translation = greedy_decode(model, sentence, arabic_vocab, english_vocab, device=device)\n",
        "        return translation\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n"
      ],
      "metadata": {
        "id": "9IxsyKYTH22U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "iface = gr.Interface(\n",
        "    fn=translate_arabic_sentence,\n",
        "    inputs=gr.Textbox(lines=2, label=\"Enter Egyptian Arabic\"),\n",
        "    outputs=gr.Textbox(label=\"English Translation\"),\n",
        "    title=\"Egyptian Arabic → English NMT (Beam Search)\",\n",
        "    description=\"Beam search decoding for more accurate translations.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True)  # Set share=True to get a public link\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 611
        },
        "id": "I7IP_r70H2zA",
        "outputId": "1c66e0fb-2b08-4070-f16a-4c0440212537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://11731ea1d75e4a1557.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://11731ea1d75e4a1557.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    }
  ]
}